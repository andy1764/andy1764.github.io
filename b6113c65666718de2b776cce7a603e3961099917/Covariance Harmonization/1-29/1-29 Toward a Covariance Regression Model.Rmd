---
title: "Toward a Covariance Regression Model"
author:
  - Andrew Chen
  - Advised by Haochang Shou and Taki Shinohara
fontsize: 16pt
always_allow_html: yes
output:
  xaringan::moon_reader:
    css: ["xaringan-themer.css"]
    nature:
      slideNumberFormat: "%current%"
  beamer_presentation:
    theme: "Szeged"
    colortheme: "dolphin"
header_includes: 
  - \usepackage{amsmath}
  - \usepackage{bm}
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(reshape2)
library(ggplot2)
library(xaringanthemer)
library(xtable)
library(lessR)
library(tableone)
library(plotly)
library(png)
library(grid)
library(psych)
library()

theme_set(theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()))
options(digits = 4)

library(RefManageR)
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "alphabetic",
           style = "markdown",
           dashed = FALSE)
myBib <- ReadBib("bibliography.bib", check = FALSE)

source("../../covbat.R", chdir = TRUE)
```

# ABCD Covariance Tests
```{r}
load("../../ABCD Example/two-sample_covtests.Rdata")
```
- Permutation tests previously suggested that considerable differences in covariance exist between Prisma and Prisma fit scanners
- Cai and Ma (2013) suggest another way to perform this two-sample test using a test statistic based on the maximum difference between entries of two covariance matrices
- For Prisma vs Prisma fit, this test statistic is `r covtest_siemens$statistic` compared against threshold of `r covtest_siemens$threshold`, so we reject the null
- For Philips Ingenia vs Achieva dStream, this test statistic is `r covtest_philips$statistic` compared against threshold of `r covtest_philips$threshold`, so we fail to reject the null

---

# Existing Covariance Regressions
- Hoff and Niu (2012) propose the following model for estimating a rank $q$ covariance effect
$$\Sigma_i = \Psi + \sum_{k=1}^q B_k \boldsymbol{x}_i \boldsymbol{x}_i^T B_k^T$$
    - $B_k$ are $r \times p$ where $r$ is the dimension of the outcome and $p$ is the dimension of the covariates
    - Likely infeasible for estimating higher rank covariance effects
- Zou et al. (2017) base their covariance regression model on modeling covariance as a sum similarity/dissimilarity matrices (e.g. subject 1 and 2 are similar if share the same gender, dissimilar otherwise)
    - Additive model, but need to carefully define the similarity matrices
    
---

# Existing Covariance Regressions
- Zhao et al. (2018) find simulatenously find directions of variation that are maximally explained by the covariates and the degree to which those covariates are related to the variance in those directions
    - Allows for flexbility in the form of covariance effects
    - Feasible for higher rank effects

---

# Proposed Covariance Regression
- We suggest a covariance regression model that is concerningly simple and only involves PCA and a heteroscedasticity model on the PC score variances
- Let $\boldsymbol{y}_1, \boldsymbol{y}_2, \ldots, \boldsymbol{y}_n$ be i.i.d. $r \times 1$ draws from a random vector $\boldsymbol{y}$ with means $\boldsymbol{\mu}_i$ and covariances $\Sigma_i$ and $\boldsymbol{x}_1, \boldsymbol{x}_2, \ldots, \boldsymbol{x}_n$ be $p \times 1$ covariate vectors
- Assume without loss of generality that $\boldsymbol{\mu}_i = \boldsymbol{0}$ for all $i$ and then perform PCA
$$\Sigma_i = \sum_{k=1}^Q \lambda_{ik} \boldsymbol{\phi}_k \boldsymbol{\phi}_k^T$$ 
- Then model the variance of PCs
$$\log(\lambda_{ik}) = \boldsymbol{x}_i^T \gamma_k$$
- So the covariance matrices are then modeled as
$$\Sigma_i = \sum_{k=1}^q \exp(\boldsymbol{x}_i^T \gamma_k) \boldsymbol{\phi}_k \boldsymbol{\phi}_k^T + E_i$$
for a rank $q$ covariance effect.

---

# Advantages/Disadvantages
- Very simple estimation, relies on nothing more than PCA and GLM estimation procedures
- Easy to obtain prediction for subjects or sets of covariates
- Confidence intervals and hypothesis can be easily derived from heteroscedasticity models (may need some multiple comparisons correction, still investigating)
- However, covariance effects limited in form to some linear combination of eigenvector outer products

---

# Initial Simulation Results
- Same situation as CovBat paper
$$\boldsymbol{y}_{ij} = \boldsymbol{\alpha} + x_{ij} \boldsymbol{\beta} + \boldsymbol{\gamma}_i + \boldsymbol{\delta}_i^T \boldsymbol{e}_{ij}$$
where $e_{ij} \sim \text{N}(\boldsymbol{0}, \Sigma + \Omega_i + x_{ij}\Psi)$
- We chose $\Psi$ to be similar to $\Omega_2$, which looks like a pig

---

# Intercept (Somewhat Positive Duck)

```{r fig.width=10, fig.height=10, fig.show='hold', fig.align='center', out.width = "70%"}
load("../../sim_cov_reg_test.Rdata")
plot_mat(cov2cor(cov_est[,,1]))
```

---

# Scanner 2 (Negative Cat)

```{r fig.width=10, fig.height=10, fig.show='hold', fig.align='center', out.width = "70%"}
plot_mat(cov2cor(cov_est[,,2]))
```

---

# Scanner 3 (Positive Pig)
```{r fig.width=10, fig.height=10, fig.show='hold', fig.align='center', out.width = "70%"}
plot_mat(cov2cor(cov_est[,,3]))
```

---

# Intercept + Covariate
```{r fig.width=10, fig.height=10, fig.show='hold', fig.align='center', out.width = "70%"}
plot_mat(cov2cor(cov_est[,,4]))
```

---

# Covariate (Negative Pig)
```{r fig.width=10, fig.height=10, fig.show='hold', fig.align='center', out.width = "70%"}
plot_mat(cov2cor(cov_est[,,4]) - cov2cor(cov_est[,,1]))
```

---

# References
```{r ref, results="asis"}
NoCite(myBib, c("cai_two-sample_2013",
                "hoff_covariance_2012",
                "zou_covariance_2017",
                "zhao_covariate_2018"))
PrintBibliography(myBib)
```
