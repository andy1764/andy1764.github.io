
@article{aitkin_modelling_1987,
  title = {Modelling {{Variance Heterogeneity}} in {{Normal Regression Using GLIM}}},
  author = {Aitkin, Murray},
  year = {1987},
  volume = {36},
  pages = {332--339},
  issn = {0035-9254},
  doi = {10.2307/2347792},
  abstract = {This paper describes and presents simple GLIM macros for the modelling of variance heterogeneity in normal regression analysis, using a log-linear regression model for the variance. The procedure is illustrated with two examples.},
  file = {C\:\\Users\\Andrew\\Google Drive\\Grad School Stuff\\Citations\\Functional Connectivity Harmonization\\Aitkin_1987_Modelling Variance Heterogeneity in Normal Regression Using GLIM.pdf},
  journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  number = {3}
}

@article{boik_spectral_2002,
  title = {Spectral {{Models}} for {{Covariance Matrices}}},
  author = {Boik, Robert J.},
  year = {2002},
  volume = {89},
  pages = {159--182},
  issn = {0006-3444},
  abstract = {A new model for the simultaneous eigenstructure of multiple covariance matrices is proposed. The model is much more flexible than existing models and subsumes most of them as special cases. A Fisher scoring algorithm for computing maximum likelihood estimates of the parameters under normality is given. Asymptotic distributions of the estimators are derived under normality as well as under arbitrary distributions having finite fourth-order cumulants. Special attention is given to elliptically contoured distributions. Likelihood ratio tests are described and sufficient conditions are given under which the test statistics are asymptotically distributed as chi-squared random variables. Procedures are derived for evaluating Bartlett corrections under normality. Some conjectures made by Flury (1988) are verified; others are refuted. A small simulation study of the adequacy of the Bartlett correction is described and the new procedures are illustrated on two datasets.},
  file = {/Users/andrewac/Google Drive/Grad School Stuff/Citations/Functional Connectivity Harmonization/Boik_2002_Spectral Models for Covariance Matrices.pdf},
  journal = {Biometrika},
  number = {1}
}

@article{cai_two-sample_2013,
  title = {Two-{{Sample Covariance Matrix Testing}} and {{Support Recovery}} in {{High}}-{{Dimensional}} and {{Sparse Settings}}},
  author = {Cai, Tony and Liu, Weidong and Xia, Yin},
  year = {2013},
  month = mar,
  volume = {108},
  pages = {265--277},
  issn = {0162-1459},
  doi = {10.1080/01621459.2012.758041},
  abstract = {In the high-dimensional setting, this article considers three interrelated problems: (a) testing the equality of two covariance matrices  and ; (b) recovering the support of ; and (c) testing the equality of  and  row by row. We propose a new test for testing the hypothesis H 0:  and investigate its theoretical and numerical properties. The limiting null distribution of the test statistic is derived and the power of the test is studied. The test is shown to enjoy certain optimality and to be especially powerful against sparse alternatives. The simulation results show that the test significantly outperforms the existing methods both in terms of size and power. Analysis of a prostate cancer dataset is carried out to demonstrate the application of the testing procedures. When the null hypothesis of equal covariance matrices is rejected, it is often of significant interest to further investigate how they differ from each other. Motivated by applications in genomics, we also consider recovering the support of  and testing the equality of the two covariance matrices row by row. New procedures are introduced and their properties are studied. Applications to gene selection are also discussed. Supplementary materials for this article are available online.},
  file = {/Users/andrewac/Zotero/storage/GCPLD6KQ/01621459.2012.html},
  journal = {Journal of the American Statistical Association},
  number = {501}
}

@article{cook_covariance_2008,
  title = {Covariance Reducing Models: {{An}} Alternative to Spectral Modelling of Covariance Matrices},
  shorttitle = {Covariance Reducing Models},
  author = {Cook, R. Dennis and Forzani, Liliana},
  year = {2008},
  month = dec,
  volume = {95},
  pages = {799--812},
  issn = {0006-3444},
  doi = {10.1093/biomet/asn052},
  abstract = {Abstract.  We introduce covariance reducing models for studying the sample covariance matrices of a random vector observed in different populations. The models},
  file = {/Users/andrewac/Google Drive/Grad School Stuff/Citations/Functional Connectivity Harmonization/Cook_Forzani_2008_Covariance reducing models.pdf;/Users/andrewac/Zotero/storage/5LUTX4SB/262858.html},
  journal = {Biometrika},
  language = {en},
  number = {4}
}

@article{harvey_estimating_1976,
  title = {Estimating {{Regression Models}} with {{Multiplicative Heteroscedasticity}}},
  author = {Harvey, A. C.},
  year = {1976},
  month = may,
  volume = {44},
  pages = {461--465},
  issn = {00129682},
  abstract = {A regression model in which the disturbances exhibit a certain type of heteroscedasticity is considered. Maximum likelihood methods of estimation are developed and compared with the two-step estimation procedure. A likelihood ratio test for heteroscedasticity is suggested.},
  copyright = {Copyright Econometric Society May 1976},
  file = {C\:\\Users\\Andrew\\Google Drive\\Grad School Stuff\\Citations\\Functional Connectivity Harmonization\\Harvey_1976_Estimating Regression Models with Multiplicative Heteroscedasticity.pdf},
  journal = {Econometrica (pre-1986); Evanston},
  keywords = {Business And Economics},
  language = {English},
  number = {3}
}

@article{hoff_covariance_2012,
  title = {A {{COVARIANCE REGRESSION MODEL}}},
  author = {Hoff, Peter D. and Niu, Xiaoyue},
  year = {2012},
  volume = {22},
  pages = {729--753},
  issn = {1017-0405},
  abstract = {Classical regression analysis relates the expectation of a response variable to a linear combination of explanatory variables. In this article, we propose a covariance regression model that parameterizes the covariance matrix of a multivariate response vector as a parsimonious quadratic function of explanatory variables. The approach is analogous to the mean regression model, and is similar to a factor analysis model in which the factor loadings depend on the explanatory variables. Using a random-effects representation, parameter estimation for the model is straightforward using either an EM-algorithm or an MCMC approximation via Gibbs sampling. The proposed methodology provides a simple but flexible representation of heteroscedasticity across the levels of an explanatory variable, improves estimation of the mean function and gives better calibrated prediction regions when compared to a homoscedastic model.},
  file = {/Users/andrewac/Google Drive/Grad School Stuff/Citations/Functional Connectivity Harmonization/Hoff_Niu_2012_A COVARIANCE REGRESSION MODEL.pdf},
  journal = {Statistica Sinica},
  number = {2}
}

@article{lin_modeling_2019,
  title = {Modeling {{Symmetric Positive Definite Matrices}} with {{An Application}} to {{Functional Brain Connectivity}}},
  author = {Lin, Zhenhua and Kong, Dehan and Sun, Qiang},
  year = {2019},
  month = jul,
  abstract = {In neuroscience, functional brain connectivity describes the connectivity between brain regions that share functional properties. Neuroscientists often characterize it by a time series of covariance matrices between functional measurements of distributed neuron areas. An effective statistical model for functional connectivity and its changes over time is critical for better understanding the mechanisms of brain and various neurological diseases. To this end, we propose a matrix-log mean model with an additive heterogeneous noise for modeling random symmetric positive definite matrices that lie in a Riemannian manifold. The heterogeneity of error terms is introduced specifically to capture the curved nature of the manifold. We then propose to use the local scan statistics to detect change patterns in the functional connectivity. Theoretically, we show that our procedure can recover all change points consistently. Simulation studies and an application to the Human Connectome Project lend further support to the proposed methodology.},
  archivePrefix = {arXiv},
  eprint = {1907.03385},
  eprinttype = {arxiv},
  file = {/Users/andrewchen/Google Drive/Grad School Stuff/Citations/Functional Connectivity Harmonization/Lin et al_2019_Modeling Symmetric Positive Definite Matrices with An Application to Functional.pdf;/Users/andrewac/Zotero/storage/JB64HPIB/1907.html},
  journal = {arXiv:1907.03385 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{niu_joint_2019,
  title = {{{JOINT MEAN AND COVARIANCE MODELING OF MULTIPLE HEALTH OUTCOME MEASURES}}},
  author = {NIU, XIAOYUE and HOFF, PETER D.},
  year = {2019},
  month = mar,
  volume = {13},
  pages = {321--339},
  issn = {1932-6157},
  doi = {10.1214/18-AOAS1187},
  abstract = {Health exams determine a patient's health status by comparing the patient's measurement with a population reference range, a 95\% interval derived from a homogeneous reference population. Similarly, most of the established relation among health problems are assumed to hold for the entire population. We use data from the 2009\textendash{}2010 National Health and Nutrition Examination Survey (NHANES) on four major health problems in the U.S. and apply a joint mean and covariance model to study how the reference ranges and associations of those health outcomes could vary among subpopulations. We discuss guidelines for model selection and evaluation, using standard criteria such as AIC in conjunction with posterior predictive checks. The results from the proposed model can help identify subpopulations in which more data need to be collected to refine the reference range and to study the specific associations among those health problems.},
  file = {/Users/andrewac/Google Drive/Grad School Stuff/Citations/Covariance Regression/NIU_HOFF_2019_JOINT MEAN AND COVARIANCE MODELING OF MULTIPLE HEALTH OUTCOME MEASURES.pdf},
  journal = {The annals of applied statistics},
  number = {1},
  pmcid = {PMC6699761},
  pmid = {31428218}
}

@article{pomann_two_2016,
  title = {A {{Two Sample Distribution}}-{{Free Test}} for {{Functional Data}} with {{Application}} to a {{Diffusion Tensor Imaging Study}} of {{Multiple Sclerosis}}},
  author = {Pomann, Gina-Maria and Staicu, Ana-Maria and Ghosh, Sujit},
  year = {2016},
  month = apr,
  volume = {65},
  pages = {395--414},
  issn = {0035-9254},
  doi = {10.1111/rssc.12130},
  abstract = {Motivated by an imaging study, this paper develops a nonparametric testing procedure for testing the null hypothesis that two samples of curves observed at discrete grids and with noise have the same underlying distribution. The objective is to formally compare white matter tract profiles between healthy individuals and multiple sclerosis patients, as assessed by conventional diffusion tensor imaging measures. We propose to decompose the curves using functional principal component analysis of a mixture process, which we refer to as marginal functional principal component analysis. This approach reduces the dimension of the testing problem in a way that enables the use of traditional nonparametric univariate testing procedures. The procedure is computationally efficient and accommodates different sampling designs. Numerical studies are presented to validate the size and power properties of the test in many realistic scenarios. In these cases, the proposed test has been found to be more powerful than its primary competitor. Application to the diffusion tensor imaging data reveals that all the tracts studied are associated with multiple sclerosis and the choice of the diffusion tensor image measurement is important when assessing axonal disruption.},
  file = {/Users/andrewac/Google Drive/Grad School Stuff/Citations/Functional Connectivity Harmonization/Pomann et al_2016_A Two Sample Distribution-Free Test for Functional Data with Application to a.pdf},
  journal = {Journal of the Royal Statistical Society. Series C, Applied statistics},
  number = {3},
  pmcid = {PMC4812165},
  pmid = {27041772}
}

@article{pourahmadi_covariance_2011,
  title = {Covariance {{Estimation}}: {{The GLM}} and {{Regularization Perspectives}}},
  shorttitle = {Covariance {{Estimation}}},
  author = {Pourahmadi, Mohsen},
  year = {2011},
  month = aug,
  volume = {26},
  pages = {369--387},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/11-STS358},
  abstract = {Finding an unconstrained and statistically interpretable reparameterization of a covariance matrix is still an open problem in statistics. Its solution is of central importance in covariance estimation, particularly in the recent high-dimensional data environment where enforcing the positive-definiteness constraint could be computationally expensive. We provide a survey of the progress made in modeling covariance matrices from two relatively complementary perspectives: (1) generalized linear models (GLM) or parsimony and use of covariates in low dimensions, and (2) regularization or sparsity for high-dimensional data. An emerging, unifying and powerful trend in both perspectives is that of reducing a covariance estimation problem to that of estimating a sequence of regression problems. We point out several instances of the regression-based formulation. A notable case is in sparse estimation of a precision matrix or a Gaussian graphical model leading to the fast graphical LASSO algorithm. Some advantages and limitations of the regression-based Cholesky decomposition relative to the classical spectral (eigenvalue) and variance-correlation decompositions are highlighted. The former provides an unconstrained and statistically interpretable reparameterization, and guarantees the positive-definiteness of the estimated covariance matrix. It reduces the unintuitive task of covariance estimation to that of modeling a sequence of regressions at the cost of imposing an a priori order among the variables. Elementwise regularization of the sample covariance matrix such as banding, tapering and thresholding has desirable asymptotic properties and the sparse estimated covariance matrix is positive definite with probability tending to one for large samples and dimensions.},
  file = {/Users/andrewac/Google Drive/Grad School Stuff/Citations/Functional Connectivity Harmonization/Pourahmadi_2011_Covariance Estimation.pdf;/Users/andrewac/Zotero/storage/A7H4NRZP/1320066926.html},
  journal = {Statistical Science},
  keywords = {Bayesian estimation,Cholesky decomposition,dependence and correlation,graphical models,longitudinal data,parsimony,penalized likelihood,precision matrix,sparsity,spectral decomposition,variance-correlation decomposition},
  language = {EN},
  mrnumber = {MR2917961},
  number = {3},
  zmnumber = {1246.62139}
}

@article{pourahmadi_simultaneous_2007,
  title = {{Simultaneous modelling of the Cholesky decomposition of several covariance matrices}},
  author = {Pourahmadi, Mohsen and Daniels, Michael J. and Park, Trevor},
  year = {2007},
  month = mar,
  volume = {98},
  pages = {568--587},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2005.11.002},
  file = {/Users/andrewac/Google Drive/Grad School Stuff/Citations/Functional Connectivity Harmonization/Pourahmadi et al_2007_Simultaneous modelling of the Cholesky decomposition of several covariance.pdf;/Users/andrewac/Zotero/storage/49JEZDUX/simultaneous-modelling-of-the-cholesky-decomposition-of-several-c.html},
  journal = {Journal of Multivariate Analysis},
  language = {English (US)},
  number = {3}
}

@article{seiler_multivariate_2017,
  title = {Multivariate {{Heteroscedasticity Models}} for {{Functional Brain Connectivity}}},
  author = {Seiler, Christof and Holmes, Susan},
  year = {2017},
  volume = {11},
  issn = {1662-453X},
  doi = {10.3389/fnins.2017.00696},
  abstract = {Functional brain connectivity is the co-occurrence of brain activity in different areas during resting and while doing tasks. The data of interest are multivariate timeseries measured simultaneously across brain parcels using resting-state fMRI (rfMRI). We analyze functional connectivity using two heteroscedasticity models. Our first model is low-dimensional and scales linearly in the number of brain parcels. Our second model scales quadratically. We apply both models to data from the Human Connectome Project (HCP) comparing connectivity between short and conventional sleepers. We find stronger functional connectivity in short than conventional sleepers in brain areas consistent with previous findings. This might be due to subjects falling asleep in the scanner. Consequently, we recommend the inclusion of average sleep duration as a covariate to remove unwanted variation in rfMRI studies. A power analysis using the HCP data shows that a sample size of 40 detects 50\% of the connectivity at a false discovery rate of 20\%. We provide implementations using R and the probabilistic programming language Stan.},
  file = {C\:\\Users\\Andrew\\Google Drive\\Grad School Stuff\\Citations\\Functional Connectivity Harmonization\\Seiler_Holmes_2017_Multivariate Heteroscedasticity Models for Functional Brain Connectivity.pdf},
  journal = {Frontiers in Neuroscience},
  keywords = {Bayesian Analysis,Covariance regression,functional connectivity,heteroscedasticity,sleep duration},
  language = {English}
}

@article{verbyla_modelling_1993,
  title = {Modelling {{Variance Heterogeneity}}: {{Residual Maximum Likelihood}} and {{Diagnostics}}},
  shorttitle = {Modelling {{Variance Heterogeneity}}},
  author = {Verbyla, A. P.},
  year = {1993},
  volume = {55},
  pages = {493--508},
  issn = {2517-6161},
  doi = {10.1111/j.2517-6161.1993.tb01918.x},
  abstract = {The assumption of equal variance in the normal regression model is not always appropriate. to attempt to eliminate unequal variance a transformation is often used but if the transformation is not successful, or the variances are of intrinsic interest, it may be necessary to model the variances in some way. We consider the normal regression model when log-linear dependence of the variances on explanatory variables is suspected. Detection of the dependence, estimation and tests of homogeneity based on full and residual maximum likelihood are discussed as are regression diagnostic methods based on case deletion and log-likelihood displacement. Whereas the behaviour of full and residual maximum likelihood is similar under case deletion, changes in residual maximum likelihood estimates and log-likelihood displacements tend to be smaller than maximum likelihood.},
  copyright = {\textcopyright{} 1993 Royal Statistical Society},
  file = {/Users/andrewac/Google Drive/Grad School Stuff/Citations/Functional Connectivity Harmonization/Verbyla_1993_Modelling Variance Heterogeneity - Residual Maximum Likelihood and Diagnostics.pdf;/Users/andrewac/Zotero/storage/J9APCDWN/j.2517-6161.1993.tb01918.html},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  keywords = {diagnostics,log-linear model,maximum likelihood,regression,residual maximum likelihood,score test,variance heterogeneity,variance model},
  language = {en},
  number = {2}
}

@article{zhao_covariate_2018,
  title = {Covariate {{Assisted Principal Regression}} for {{Covariance Matrix Outcomes}}},
  author = {Zhao, Yi and Wang, Bingkai and Mostofsky, Stewart and Caffo, Brian and Luo, Xi},
  year = {2018},
  pages = {425033},
  file = {C\:\\Users\\Andrew\\Google Drive\\Grad School Stuff\\Citations\\Functional Connectivity Harmonization\\Zhao_2018_Covariate Assisted Principal Regression for Covariance Matrix Outcomes.pdf},
  journal = {bioRxiv}
}

@article{zou_covariance_2017,
  title = {Covariance {{Regression Analysis}}},
  author = {Zou, Tao and Lan, Wei and Wang, Hansheng and Tsai, Chih-Ling},
  year = {2017},
  month = jan,
  volume = {112},
  pages = {266--281},
  issn = {0162-1459},
  doi = {10.1080/01621459.2015.1131699},
  abstract = {This article introduces covariance regression analysis for a p-dimensional response vector. The proposed method explores the regression relationship between the p-dimensional covariance matrix and auxiliary information. We study three types of estimators: maximum likelihood, ordinary least squares, and feasible generalized least squares estimators. Then, we demonstrate that these regression estimators are consistent and asymptotically normal. Furthermore, we obtain the high dimensional and large sample properties of the corresponding covariance matrix estimators. Simulation experiments are presented to demonstrate the performance of both regression and covariance matrix estimates. An example is analyzed from the Chinese stock market to illustrate the usefulness of the proposed covariance regression model. Supplementary materials for this article are available online.},
  file = {/Users/andrewac/Google Drive/Grad School Stuff/Citations/Covariance Regression/Zou et al_2017_Covariance Regression Analysis.pdf;/Users/andrewac/Zotero/storage/5JFXWHH3/01621459.2015.html},
  journal = {Journal of the American Statistical Association},
  number = {517}
}


